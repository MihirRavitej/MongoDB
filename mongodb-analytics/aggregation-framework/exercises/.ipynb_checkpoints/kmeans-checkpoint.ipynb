{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies Installation\n",
    "Before we get started, let's make sure we have all dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "!{sys.executable} =m pip install pymongo dateparser sklearn pandas numpy pprint scipy matplotlib seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: k-means Clustering\n",
    "\n",
    "Your task is to explore the titanic dataset in the course Atlas cluster using the k-means clustering algorithm. We've used KMeans from sklearn.\n",
    "\n",
    "Most of the work is done for you. \n",
    "\n",
    "You will have to marshall the data from MongoDB and create a Pandas DataFrame, then select values to feed into the KMeans algorithm.\n",
    "\n",
    "Aside from `survived`, what single feature (attribute) seems to have the largest impact on survival?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import dateparser\n",
    "import pymongo\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pymongo Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymongo driver configuration\n",
    "course_cluster_uri = \"mongodb://agg-student:agg-password@cluster0-shard-00-00-jxeqq.mongodb.net:27017,cluster0-shard-00-01-jxeqq.mongodb.net:27017,cluster0-shard-00-02-jxeqq.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin\"\n",
    "course_client = pymongo.MongoClient(course_cluster_uri)\n",
    "titanic = course_client['coursera-agg']['titanic']\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting our data from MongoDB\n",
    "\n",
    "We need to construct an aggregation pipeline to get our data from MongoDB. Within this pipeline, we'll also perform some data transformations to ensure we only get numeric values back and ensure that we have no missing values. We must have only numeric values for simple k-means.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keys and Sets\n",
    "\n",
    "To get all of the keys possible, we'll use a `$group` stage to collect all keys encountered. We'll do this by using the `$map` expression, converting the object to an array and using that as the input, and then extracting only the key value.\n",
    "\n",
    "We're also getting sets of all the non-numeric fields we have. This is so we can later assign these values a numeric value later, specifically its index in the set!\n",
    "\n",
    "Lastly, we are also gathering the `_id` of documents encountered so we can perform a later `$lookup`. We do this rather than pushing the entire document into an array to keep memory and/or disk impact as low as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_analysis_and_set_building = {\n",
    "    \"$group\": {\n",
    "            \"_id\":  0,\n",
    "            \"all_keys\": {\n",
    "                \"$addToSet\": {\n",
    "                    \"$map\": {\n",
    "                        \"input\": {\"$objectToArray\": \"$$CURRENT\"},\n",
    "                        \"in\": \"$$this.k\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"source_ids\": {\n",
    "                \"$push\": \"$$CURRENT._id\"\n",
    "            },\n",
    "            \"name_set\": {\"$addToSet\": \"$name\"},\n",
    "            \"gender_set\": {\"$addToSet\": \"$gender\"},\n",
    "            \"point_of_embarkation_set\": {\"$addToSet\": \"$point_of_embarkation\"},\n",
    "            \"ticket_number_set\": {\"$addToSet\": \"$ticket_number\"},\n",
    "            \"cabin_set\": {\"$addToSet\": \"$cabin\"}\n",
    "        }\n",
    "}\n",
    "pprint.pprint(key_analysis_and_set_building)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "We now have an array of keys that is an array of arrays that are all keys encountered on documents. We now have to clean this up to create a flat array that has no duplicate values. This will result in an array of every key encountered, no less and no more.\n",
    "\n",
    "To accomplish this, we use the `$reduce` expression, specifying the `all_keys` array we just created as the input. We give it an initial value of an empty array, and then use the `$setUnion` operator to ensure we don't have any duplicates. This will result in a flat array of unique keys, exactly what we want.\n",
    "\n",
    "### Wouldn't it have been more simple to just provide these keys statically?\n",
    "Sure, assuming you knew what all the keys were. What if there were hundreds or thousands of keys?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_all_keys = {\n",
    "    \"$addFields\": {\n",
    "        \"all_keys\": {\n",
    "            \"$reduce\": {\n",
    "                \"input\": \"$all_keys\",\n",
    "                \"initialValue\": [],\n",
    "                \"in\": {\n",
    "                    \"$setUnion\": [\"$$value\", \"$$this.k\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unwinding `source_ids`\n",
    "We now unwind the `ObjectId`s in `source_ids` to perform our lookup. This creates a new document for every element that was in `$source_ids`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_unwind = {\n",
    "    \"$unwind\": \"$source_ids\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup and Second Unwind\n",
    "\n",
    "We then use `$lookup` to build up our documents again. We're guaranteed only one document per lookup because we are using `_id`, which has a unique constraint in the database. We immediately follow with an `$unwind` stage.\n",
    "\n",
    "Internally, these are coalesced so really are one stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookup = {\n",
    "    \"$lookup\": {\n",
    "        \"from\": \"titanic\",\n",
    "        \"localField\": \"source_ids\",\n",
    "        \"foreignField\": \"_id\",\n",
    "        \"as\": \"source_docs\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_unwind = {\n",
    "    \"$unwind\": \"$source_docs\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in Missing Values\n",
    "\n",
    "We have to fill in missing values from the current document. To do this, we iterate over the difference between `all_keys` that we calculated previously, and an object called `$$curent_obj` that will be provided for us.\n",
    "\n",
    "We set the initial value to `current_obj`, and then append the missing keys with default values of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fill_missing_with_0 = {\n",
    "    \"$reduce\": {\n",
    "        \"input\": {\n",
    "            \"$setDifference\": [\"$all_keys\", \"$$current_obj\"]\n",
    "        },\n",
    "        \"initialValue\": \"$$current_obj\",\n",
    "        \"in\": {\"$concatArrays\": [\"$$value\", [{\"k\": \"$$this\", \"v\": 0}]]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Index of non-numerics\n",
    "\n",
    "We create a utility function that will return the proper `case` statement to use in a `$switch` expression which will be used below. String interpolation is used to ensure we check the value of the correct key and fetch the index from the correct set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def key_case(key_name):\n",
    "    return {\n",
    "        \"case\": {\n",
    "            \"$eq\": [\"$$this.k\", f\"{key_name}\"]\n",
    "        },\n",
    "        \"then\": {\n",
    "            \"$concatArrays\": [\n",
    "                \"$$value\",\n",
    "                [\n",
    "                    {\n",
    "                        \"k\": \"$$this.k\",\n",
    "                        \"v\": {\n",
    "                            \"$indexOfArray\": [\n",
    "                                f\"${key_name}_set\",\n",
    "                                \"$$this.v\"\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            ]\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting non-numerics\n",
    "\n",
    "This may appear to be the longest and most complicated, but appearances can be deceiving.\n",
    "\n",
    "We use `$reduce`, specifying as input the result of the `$reduce` expression used in the `fill_missing_with_0` variable.\n",
    "- For the initial value, we specify an empty array that we can then store key/value pairs in that will ultimately be returned to the `$arrayToObject` expression.\n",
    "- Within `in` we have our `$switch` statement. We use the `key_case` helper function created earlier to get the proper cases for the name, gender, ticket_number, point_of_embarkation, and cabin. For age we have a case that checks to see if the age is an empty string. If it is, we assign a default value of 0. Lastly, for the default case we just pass the key/value pair through and add them to the accumulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_non_numerics = {\n",
    "    \"$reduce\": {\n",
    "        \"input\": fill_missing_with_0,\n",
    "        \"initialValue\": [],\n",
    "        \"in\": {\n",
    "            \"$switch\": {\n",
    "                \"branches\": [\n",
    "                    key_case(\"name\"),\n",
    "                    key_case(\"gender\"),\n",
    "                    key_case(\"ticket_number\"),\n",
    "                    key_case(\"point_of_embarkation\"),\n",
    "                    key_case(\"cabin\"),\n",
    "                    {\n",
    "                        \"case\": {\n",
    "                            \"$and\": [\n",
    "                                {\"$eq\": [\n",
    "                                    \"$$this.k\", \"age\"]},\n",
    "                                {\"$eq\": [\n",
    "                                    \"$$this.v\", \"\"]}\n",
    "                            ]\n",
    "                        },\n",
    "                        \"then\": {\n",
    "                            \"$concatArrays\": [\n",
    "                                \"$$value\",\n",
    "                                [{\n",
    "                                    \"k\": \"$$this.k\",\n",
    "                                    \"v\": 0\n",
    "                                }]\n",
    "                            ]}\n",
    "                    }\n",
    "                ],\n",
    "                \"default\": {\n",
    "                    \"$concatArrays\": [\"$$value\", [\"$$this\"]]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Stage\n",
    "\n",
    "This is the stage that will use the `convert_non_numerics` variable we just defined.\n",
    "\n",
    "The `$replaceRoot` stage will replace the current document with the results of the expression provided to `newRoot`, which is using `$arrayToObject`, converting the array of key/value pairs back to an object.\n",
    "\n",
    "Notice the use of the `$let` expression here, allowing us to define a variable for use within its scope. This is where the `current_obj` value is being created used in `fill_missing_with_0` and `convert_non_numerics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cleaning = {\n",
    "    \"$replaceRoot\": {\n",
    "        \"newRoot\": {\n",
    "            \"$arrayToObject\": {\n",
    "                \"$let\": {\n",
    "                    \"vars\": {\n",
    "                        \"current_obj\": {\"$objectToArray\": \"$source_docs\"}\n",
    "                    },\n",
    "                    \"in\": convert_non_numerics\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Fields\n",
    "\n",
    "Lastly, we have the final `$project` stage that will remove fields returned to us. `_id` should have no impact on clustering. What other fields might be more noise than value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redacting_project = {\n",
    "    \"$project\": {\n",
    "        \"_id\": 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Pipeline\n",
    "\n",
    "We now construct the pipeline from our variables that represent stages: `redacting_project`, `data_cleaning`, `lookup_and_unwind`, `first_unwind`, `get_all_keys`, `key_analysis_and_set_building`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    key_analysis_and_set_building,\n",
    "    get_all_keys,\n",
    "    first_unwind,\n",
    "    lookup,\n",
    "    second_unwind,\n",
    "    data_cleaning,\n",
    "    redacting_project\n",
    "]\n",
    "print(json.dumps(pipeline, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the pandas Dataframe from MongoDB\n",
    "\n",
    "Here you will need to construct the DataFrame. Assign it to the variabled `df` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo - construct the pandas dataframe!\n",
    "df = \n",
    "df.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can play around with the different axes and plotting fields to visualize the data set\n",
    "df.plot.scatter(y='age', x='point_of_embarkation', c=\"cabin\", s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for KMeans\n",
    "\n",
    "First, a numpy array is created from the DataFrame. The **survived** column is dropped, because providing it to the clustering algorithm would simply give the algorithm too much information. We want to make the computer find common traits that survivors have, aside from that they survived!\n",
    "\n",
    "Then, the data is scaled. This increases accuracy because it reduces the size of the numbers while still retaining accuracy, ultimatey meaning smaller shifts in centroid movement as KMeans attempts to find the clusters.\n",
    "\n",
    "Lastly, a numpy array is created that is **only** the survived column. This will be used to measure the accuracy with the given features we supplied in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns here to send into the KMeans function\n",
    "# experiment with removing different columns. For example, is the name of the passenger important? And should\n",
    "# we drop it here, or perhaps project it away in our query operation to MongoDB?\n",
    "X = np.array(df.drop(['survived'], axis=1)).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the X axis\n",
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a numpy array that is just the survived column to compare accuracy\n",
    "y = np.array(df[['survived']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans in Action\n",
    "\n",
    "Finally, the KMeans algorithm is used and accuracy is measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want two clusters. There's no way to tell the computer how we want it to cluster\n",
    "# the groups, so we are hoping that the clusters it finds map to \"survived\" or \"perished\"\n",
    "clf = KMeans(n_clusters=2, n_init=20)\n",
    "clf.fit(X)\n",
    "predict = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot information from the dataframe to get an idea of how data correlates\n",
    "\n",
    "# Play around with the x and y. What if you change x to gender?\n",
    "sns.swarmplot(x=\"point_of_embarkation\", y=\"age\", hue=\"survived\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"gender\", y=\"age\", hue=\"survived\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"point_of_embarkation\", y=\"fare_paid\", hue=\"survived\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"ticket_number\", y=\"age\", hue=\"survived\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using seaborn's PairGrid to plot multiple attributes against eachother\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "g = sns.PairGrid(df[['survived', 'class', 'age', 'gender']])\n",
    "g = g.map_upper(sns.kdeplot, cmap='bwr', shade=True)\n",
    "g = g.map_lower(sns.kdeplot, cmap=\"hot\",shade=True)\n",
    "g = g.map_diag(sns.countplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score the clustering algorithm, do not change\n",
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = clf.predict(predict_me)\n",
    "    if prediction[0] == y[i]:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the clustering is binary, the label it assigns to a group (0 or 1) isn't relevant\n",
    "# the fact that it grouped similar entries together is what is significant\n",
    "# this corrects the accuracy so that it is always shown as the greater % correct\n",
    "accuracy = correct/len(X)\n",
    "if accuracy < .50:\n",
    "    accuracy = 1 - accuracy\n",
    "\n",
    "print(\"Correct survival grouping: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
